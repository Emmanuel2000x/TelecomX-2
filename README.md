# üìä Proyecto TelecomX -- An√°lisis y Modelado de Cancelaci√≥n de Clientes

## üìå Descripci√≥n

Este proyecto tiene como objetivo analizar los datos de clientes de
**TelecomX** y construir modelos predictivos que permitan anticipar la
**cancelaci√≥n de servicios** (churn).

El flujo de trabajo fue el siguente:

## 1. **Carga y exploraci√≥n de datos**
A partir del archivo `Datos_Mod_TelecomX.csv` obtenido en el proyecto **TelecomX-Parte1**
## 2. **Limpieza y preparaci√≥n** de la informaci√≥n:
- Eliminaci√≥n de valores nulos.\
- Codificaci√≥n de variables categ√≥ricas.
- Balanceo de clases con **SMOTE**.
## 3. **An√°lisis exploratorio de datos (EDA):**\
- Boxplots, histogramas y distribuciones de variables.
- Comparaciones entre clientes activos y cancelados.
## 4. **Entrenamiento de modelos de Machine Learning:**
- `LogisticRegression`
- `SVC`
- `RandomForestClassifier`
- `XGBClassifier`
## 5. **Optimizaci√≥n de hiperpar√°metros** con **GridSearchCV** y **validaci√≥n cruzada**.
Para este proyecto las variables de entrenamiento fueron divididas en 5 grupos y la 
metrica sobre la que se entrenaron los modelos al haber balanceado  los resgistros fue
*f1*
## 6. **Evaluaci√≥n de desempe√±o** usando m√©tricas de clasificaci√≥n:
- Exactitud (Accuracy)
- Precisi√≥n (Precision)
- Recall
- F1-score
## 7. **Interpretabilidad del modelo:**
Se realiza el an√°lisis de las variables m√°s relevantes para la predicci√≥n de la cancelaci√≥n:
- Importancia de variables en Random Forest y XGBoost.
- Coeficientes de Logistic Regression y SVC.
- Visualizaci√≥n con gr√°ficos de barras.
## **Conclusiones**
Despues del entrenamiento los modelos tubieron los siguientes resultados: 

| Model	                  | F1-score (Avg) Train | F1-score Test | Variaci√≥n |
|-------------------------|----------------------|---------------|-----------|
| Logistic Regression     | 0.79                 | 0.71	         | -10.1%    |
| Support Vector Machine  | 0.72 	             | 0.60          | -16.6%    |
| Random Forest	          | 0.82                 | 0.73          | -10.9%   |
| XGBoost Classifier      | 0.82 	             | 0.73          | -10.9%   | 
------------------------------------------------------------------------
Los modelos Random forest y XGBoost fueron los que entregaron mejores resultados tanto en el 
entrenamiento como con los datos de prueba 
## üìÇ Archivos del proyecto

-   **`TelecomX_2.ipynb`** ‚Üí Notebook principal con todo el flujo de
    an√°lisis, modelado y evaluaci√≥n.\
-   **`Datos_Mod_TelecomX.csv`** ‚Üí Dataset procesado de clientes de
    TelecomX.

------------------------------------------------------------------------

## ‚öôÔ∏è Requisitos

Este proyecto fue desarrollado en **Python 3.x** y requiere las
siguientes librer√≠as:

``` bash
pip install numpy pandas matplotlib seaborn scikit-learn imbalanced-learn xgboost
```

------------------------------------------------------------------------

## ‚ñ∂Ô∏è Ejecuci√≥n

1.  Clona este repositorio o descarga los archivos.\
2.  Aseg√∫rate de tener el archivo `Datos_Mod_TelecomX.csv` en la misma
    carpeta que el notebook.\
3.  Abre y ejecuta el notebook `TelecomX_2.ipynb` en Jupyter Notebook o
    Google Colab.

------------------------------------------------------------------------

## üôå Autor

Proyecto desarrollado por **Sergio Uribe** como parte de un ejercicio de
an√°lisis y modelado de datos.
